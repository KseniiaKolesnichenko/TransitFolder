{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open ('dataset.txt',encoding='UTF-8') as file:\n",
    "#    lines = file.readlines()\n",
    "#    lines = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('data.xlsx', dtype=object)\n",
    "#for line in lines:\n",
    "#    tags=line.split(' ',1)[0]\n",
    "#    for tag in tags.split(','):\n",
    "#        data.append([tag.replace('__label__',''),line.split(' ',1)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 778 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def clean(txt):\n",
    "    lst = re.sub('[^А-Яа-яa-zA-Z]+', ' ', str(txt)).lower()\n",
    "\n",
    "    return lst\n",
    "\n",
    "data['TEXT']=data['TEXT'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>скотина что сказать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>заколоть этого плешивого урода что бы крякнул ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>THREAT</td>\n",
       "      <td>заколоть этого плешивого урода что бы крякнул ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>долбоебы это фэйк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>пиздаболы сделали снимок придумали историю и п...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  TARGET                                               TEXT\n",
       "0          0  INSULT                                скотина что сказать\n",
       "1          7  INSULT  заколоть этого плешивого урода что бы крякнул ...\n",
       "2          8  THREAT  заколоть этого плешивого урода что бы крякнул ...\n",
       "3         25  INSULT                                  долбоебы это фэйк\n",
       "4         26  INSULT  пиздаболы сделали снимок придумали историю и п..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INSULT       36826\n",
       "NORMAL       20000\n",
       "THREAT       12027\n",
       "OBSCENITY     4261\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.DataFrame(data)\n",
    "#data.columns=['TARGET','TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.concat([data[data['TARGET'].isin(['INSULT','THREAT','OBSCENITY'])],data[data['TARGET']=='NORMAL'].head(20000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(txt):\n",
    "    lst = re.sub('[^А-Яа-яa-zA-Z]+', ' ', txt).lower() #оставляет только А-я, A-z\n",
    "    lst = lst.split(' ')\n",
    "\n",
    "    words = []\n",
    "    \n",
    "    for word in lst:\n",
    "        p = morph.parse(word)[0]\n",
    "        words.append(p.normal_form)\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctest= CountVectorizer()\n",
    "#ftest=TfidfVectorizer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = 'word','char'\n",
    "\n",
    "# max_df\n",
    "# min_df\n",
    "# max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'скотина что сказать'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.TEXT.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'скотина что сказать'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(data.TEXT.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_custom_loss_func(y_true, y_pred):\n",
    "#     error=np.abs((y_true - y_pred)/y_true)\n",
    "#     return np.mean(error)*100\n",
    "\n",
    "# my_scorer = make_scorer(my_custom_loss_func,greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linspace(1000,10000,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),    \n",
    "    ('sgd', SGDClassifier())\n",
    "    ])\n",
    "\n",
    "\n",
    "cv_params = dict([\n",
    "    ('vec__analyzer', ['word','char']),\n",
    "    ('vec__ngram_range',[(1,1),(1,2)]  ),\n",
    "    ('vec__max_features',np.linspace(1000,10000,4).astype(int)) ,\n",
    "    ('vec__sublinear_tf',[True,False]  ),\n",
    "    ('sgd__alpha', 10.0**np.arange(-4,1)),\n",
    "    ('sgd__loss', ['modified_huber']),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2000.,  4000.,  6000.,  8000., 10000.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(2000,10000,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.TEXT.values, data.TARGET.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('vec', TfidfVectorizer()),\n",
       "                                             ('sgd', SGDClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'sgd__alpha': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n",
       "                                        'sgd__loss': ['modified_huber'],\n",
       "                                        'vec__analyzer': ['word', 'char'],\n",
       "                                        'vec__max_features': array([ 1000,  4000,  7000, 10000]),\n",
       "                                        'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                                        'vec__sublinear_tf': [True, False]},\n",
       "                   scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = GridSearchCV(pipe, cv_params, verbose=1, n_jobs=-1,scoring='f1_weighted', cv = 3) #запустить его, если будет время \n",
    "model = RandomizedSearchCV(pipe, cv_params, verbose=1, n_jobs=-1,scoring='f1_weighted', cv = 3, n_iter=10)\n",
    "# лучше ставить model = RandomizedSearchCV(pipe, cv_params, verbose=1, n_jobs=-1,scoring='f1_weighted', cv >5, n_iter> 100)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(max_features=10000)),\n",
       "                ('sgd', SGDClassifier(loss='modified_huber'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec__sublinear_tf': False,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__max_features': 10000,\n",
       " 'vec__analyzer': 'word',\n",
       " 'sgd__loss': 'modified_huber',\n",
       " 'sgd__alpha': 0.0001}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.754945341808874"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_[1].coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('vec', TfidfVectorizer()),\n",
       "                                             ('sgd', SGDClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'sgd__alpha': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n",
       "                                        'sgd__loss': ['modified_huber'],\n",
       "                                        'vec__analyzer': ['word', 'char'],\n",
       "                                        'vec__max_features': array([ 1000,  4000,  7000, 10000]),\n",
       "                                        'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                                        'vec__sublinear_tf': [True, False]},\n",
       "                   scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=10000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      INSULT       0.77      0.80      0.79      7342\n",
      "      NORMAL       0.82      0.89      0.86      3909\n",
      "   OBSCENITY       0.65      0.47      0.54       864\n",
      "      THREAT       0.66      0.58      0.62      2508\n",
      "\n",
      "    accuracy                           0.77     14623\n",
      "   macro avg       0.73      0.68      0.70     14623\n",
      "weighted avg       0.76      0.77      0.76     14623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "feats= model.best_estimator_.steps[0][1].get_feature_names()\n",
    "coefs= model.best_estimator_.steps[1][1].coef_\n",
    "res= pd.DataFrame()\n",
    "for coef in coefs:\n",
    "    buf_df=pd.DataFrame()\n",
    "    buf_df['feat']=feats\n",
    "    buf_df['coef']=coef\n",
    "    buf_df = buf_df.sort_values(by=['coef'],ascending=False).head(20)\n",
    "    res[model.best_estimator_.steps[1][1].classes_[i]]=buf_df.feat.values\n",
    "    i=i+1\n",
    "    \n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSULT</th>\n",
       "      <th>NORMAL</th>\n",
       "      <th>OBSCENITY</th>\n",
       "      <th>THREAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>долбо</td>\n",
       "      <td>здоровья</td>\n",
       "      <td>сосать</td>\n",
       "      <td>расстрелять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>дебилы</td>\n",
       "      <td>спасибо</td>\n",
       "      <td>трахать</td>\n",
       "      <td>убивать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>пидоры</td>\n",
       "      <td>здравствуйте</td>\n",
       "      <td>трахаться</td>\n",
       "      <td>расстрел</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>дура</td>\n",
       "      <td>праздником</td>\n",
       "      <td>вдул</td>\n",
       "      <td>расстреливать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>блядь</td>\n",
       "      <td>цена</td>\n",
       "      <td>насосала</td>\n",
       "      <td>убить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>долбоебы</td>\n",
       "      <td>красота</td>\n",
       "      <td>трахнуть</td>\n",
       "      <td>растрелять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>пидорасы</td>\n",
       "      <td>золотые</td>\n",
       "      <td>ебут</td>\n",
       "      <td>кол</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>долба</td>\n",
       "      <td>очень</td>\n",
       "      <td>трахнул</td>\n",
       "      <td>стрелять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>долбоеб</td>\n",
       "      <td>счастья</td>\n",
       "      <td>трахал</td>\n",
       "      <td>отстреливать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>долбоебов</td>\n",
       "      <td>память</td>\n",
       "      <td>сос</td>\n",
       "      <td>бить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>пиздабол</td>\n",
       "      <td>купила</td>\n",
       "      <td>отсосать</td>\n",
       "      <td>отрезать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>дебилов</td>\n",
       "      <td>пожалуйста</td>\n",
       "      <td>соси</td>\n",
       "      <td>пристрелить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>хуйло</td>\n",
       "      <td>благодарю</td>\n",
       "      <td>отсосал</td>\n",
       "      <td>повесить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ебанутые</td>\n",
       "      <td>прелесть</td>\n",
       "      <td>секс</td>\n",
       "      <td>стенке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>пидор</td>\n",
       "      <td>люблю</td>\n",
       "      <td>сиськи</td>\n",
       "      <td>отпиздить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>пиздобол</td>\n",
       "      <td>продам</td>\n",
       "      <td>дрочит</td>\n",
       "      <td>казнить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>пидарасы</td>\n",
       "      <td>август</td>\n",
       "      <td>сосет</td>\n",
       "      <td>кастрировать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>идиоты</td>\n",
       "      <td>молодцы</td>\n",
       "      <td>дрочить</td>\n",
       "      <td>отрубить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>долбаебы</td>\n",
       "      <td>любовь</td>\n",
       "      <td>трахну</td>\n",
       "      <td>растреливать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>пиздаболы</td>\n",
       "      <td>доброе</td>\n",
       "      <td>член</td>\n",
       "      <td>мочить</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       INSULT        NORMAL  OBSCENITY         THREAT\n",
       "0       долбо      здоровья     сосать    расстрелять\n",
       "1      дебилы       спасибо    трахать        убивать\n",
       "2      пидоры  здравствуйте  трахаться       расстрел\n",
       "3        дура    праздником       вдул  расстреливать\n",
       "4       блядь          цена   насосала          убить\n",
       "5    долбоебы       красота   трахнуть     растрелять\n",
       "6    пидорасы       золотые       ебут            кол\n",
       "7       долба         очень    трахнул       стрелять\n",
       "8     долбоеб       счастья     трахал   отстреливать\n",
       "9   долбоебов        память        сос           бить\n",
       "10   пиздабол        купила   отсосать       отрезать\n",
       "11    дебилов    пожалуйста       соси    пристрелить\n",
       "12      хуйло     благодарю    отсосал       повесить\n",
       "13   ебанутые      прелесть       секс         стенке\n",
       "14      пидор         люблю     сиськи      отпиздить\n",
       "15   пиздобол        продам     дрочит        казнить\n",
       "16   пидарасы        август      сосет   кастрировать\n",
       "17     идиоты       молодцы    дрочить       отрубить\n",
       "18   долбаебы        любовь     трахну   растреливать\n",
       "19  пиздаболы        доброе       член         мочить"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
